{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import operator \n",
    "\n",
    "# Add 'datatype' column that indicates if the record is original wiki answer as 0, training data 1, test data 2, onto \n",
    "# the dataframe - uses stratified random sampling (with seed) to sample by task & plagiarism amount \n",
    "\n",
    "# Use function to label datatype for training 1 or test 2 \n",
    "def create_datatype(df, train_value, test_value, datatype_var, compare_dfcolumn, operator_of_compare, value_of_compare,\n",
    "                    sampling_number, sampling_seed):\n",
    "    # Subsets dataframe by condition relating to statement built from:\n",
    "    # 'compare_dfcolumn' 'operator_of_compare' 'value_of_compare'\n",
    "    df_subset = df[operator_of_compare(df[compare_dfcolumn], value_of_compare)]\n",
    "    df_subset = df_subset.drop(columns = [datatype_var])\n",
    "    \n",
    "    # Prints counts by task and compare_dfcolumn for subset df\n",
    "    #print(\"\\nCounts by Task & \" + compare_dfcolumn + \":\\n\", df_subset.groupby(['Task', compare_dfcolumn]).size().reset_index(name=\"Counts\") )\n",
    "    \n",
    "    # Sets all datatype to value for training for df_subset\n",
    "    df_subset.loc[:, datatype_var] = train_value\n",
    "    \n",
    "    # Performs stratified random sample of subset dataframe to create new df with subset values \n",
    "    df_sampled = df_subset.groupby(['Task', compare_dfcolumn], group_keys=False).apply(lambda x: x.sample(min(len(x), sampling_number), random_state = sampling_seed))\n",
    "    df_sampled = df_sampled.drop(columns = [datatype_var])\n",
    "    # Sets all datatype to value for test_value for df_sampled\n",
    "    df_sampled.loc[:, datatype_var] = test_value\n",
    "    \n",
    "    # Prints counts by compare_dfcolumn for selected sample\n",
    "    #print(\"\\nCounts by \"+ compare_dfcolumn + \":\\n\", df_sampled.groupby([compare_dfcolumn]).size().reset_index(name=\"Counts\") )\n",
    "    #print(\"\\nSampled DF:\\n\",df_sampled)\n",
    "    \n",
    "    # Labels all datatype_var column as train_value which will be overwritten to \n",
    "    # test_value in next for loop for all test cases chosen with stratified sample\n",
    "    for index in df_sampled.index: \n",
    "        # Labels all datatype_var columns with test_value for straified test sample\n",
    "        df_subset.loc[index, datatype_var] = test_value\n",
    "\n",
    "    #print(\"\\nSubset DF:\\n\",df_subset)\n",
    "    # Adds test_value and train_value for all relevant data in main dataframe\n",
    "    for index in df_subset.index:\n",
    "        # Labels all datatype_var columns in df with train_value/test_value based upon \n",
    "        # stratified test sample and subset of df\n",
    "        df.loc[index, datatype_var] = df_subset.loc[index, datatype_var]\n",
    "\n",
    "    # returns nothing because dataframe df already altered \n",
    "    \n",
    "def train_test_dataframe(clean_df, random_seed=100):\n",
    "    \n",
    "    new_df = clean_df.copy()\n",
    "\n",
    "    # Initialize datatype as 0 initially for all records - after function 0 will remain only for original wiki answers\n",
    "    new_df.loc[:,'Datatype'] = 0\n",
    "\n",
    "    # Creates test & training datatypes for plagiarized answers (1,2,3)\n",
    "    create_datatype(new_df, 1, 2, 'Datatype', 'Category', operator.gt, 0, 1, random_seed)\n",
    "\n",
    "    # Creates test & training datatypes for NON-plagiarized answers (0)\n",
    "    create_datatype(new_df, 1, 2, 'Datatype', 'Category', operator.eq, 0, 2, random_seed)\n",
    "    \n",
    "    # creating a dictionary of categorical:numerical mappings for plagiarsm categories\n",
    "    mapping = {0:'orig', 1:'train', 2:'test'} \n",
    "\n",
    "    # traversing through dataframe and replacing categorical data\n",
    "    new_df.Datatype = [mapping[item] for item in new_df.Datatype] \n",
    "\n",
    "    return new_df\n",
    "\n",
    "\n",
    "# helper function for pre-processing text given a file\n",
    "def process_file(file):\n",
    "    # put text in all lower case letters \n",
    "    all_text = file.read().lower()\n",
    "\n",
    "    # remove all non-alphanumeric chars\n",
    "    all_text = re.sub(r\"[^a-zA-Z0-9]\", \" \", all_text)\n",
    "    # remove newlines/tabs, etc. so it's easier to match phrases, later\n",
    "    all_text = re.sub(r\"\\t\", \" \", all_text)\n",
    "    all_text = re.sub(r\"\\n\", \" \", all_text)\n",
    "    all_text = re.sub(\"  \", \" \", all_text)\n",
    "    all_text = re.sub(\"   \", \" \", all_text)\n",
    "    \n",
    "    return all_text\n",
    "\n",
    "\n",
    "def create_text_column(df, file_directory='data/'):\n",
    "    '''Reads in the files, listed in a df and returns that df with an additional column, `Text`. \n",
    "       :param df: A dataframe of file information including a column for `File`\n",
    "       :param file_directory: the main directory where files are stored\n",
    "       :return: A dataframe with processed text '''\n",
    "   \n",
    "    # create copy to modify\n",
    "    text_df = df.copy()\n",
    "    \n",
    "    # store processed text\n",
    "    text = []\n",
    "    \n",
    "    # for each file (row) in the df, read in the file \n",
    "    for row_i in df.index:\n",
    "        filename = df.iloc[row_i]['File']\n",
    "        #print(filename)\n",
    "        file_path = file_directory + filename\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "\n",
    "            # standardize text using helper function\n",
    "            file_text = process_file(file)\n",
    "            # append processed text to list\n",
    "            text.append(file_text)\n",
    "    \n",
    "    # add column to the copied dataframe\n",
    "    text_df['Text'] = text\n",
    "    \n",
    "    return text_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
